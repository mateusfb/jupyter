{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import *\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from ntpath import split, basename\n",
    "from os import stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(path, label_col = None):\n",
    "    dataframe = pd.read_csv(path)\n",
    "    if(label_col is None):\n",
    "        X = dataframe.to_numpy()\n",
    "    else:\n",
    "        X = np.array(dataframe.drop(label_col, axis = 1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(method, parameters = {}):\n",
    "    methods = {\"KMeans\" : KMeans,\n",
    "               \"AffinityPropagation\" : AffinityPropagation,\n",
    "               \"AgglormerativeClustering\" : AgglomerativeClustering,\n",
    "               \"Birch\" : Birch,\n",
    "               \"DBSCAN\" : DBSCAN,\n",
    "               \"FeatureAgglomeration\" : FeatureAgglomeration,\n",
    "               \"MiniBatchKMeans\" : MiniBatchKMeans,\n",
    "               \"MeanShift\" : MeanShift,\n",
    "               \"OPTICS\" : OPTICS,\n",
    "               \"SpectralClustering\" : SpectralClustering,\n",
    "               \"SpectralBiclustering\" : SpectralBiclustering,\n",
    "               \"SpectralCoclustering\" : SpectralCoclustering,}\n",
    "               \n",
    "    return methods[method](**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(X, labels):\n",
    "    slt_score = silhouette_score(X, labels)\n",
    "    db_score = davies_bouldin_score(X, labels)\n",
    "    return (slt_score, db_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileNameFromPath(path):\n",
    "    head, tail = split(path)\n",
    "    return tail or basename(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeData(file_name, slt_score, db_score, k = '-', seed = '-'): \n",
    "    file = open(file_name, 'a')\n",
    "    if(stat(file_name).st_size == 0):\n",
    "        file.write(\"n_cluster,seed,silhoutte,db\\n\")\n",
    "    \n",
    "    file.write(k + ',' + seed + ',' + slt_score + ',' + db_score + '\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(path, method, parameters = {}, k_range = None, seed_range = None, label_col = None, ):\n",
    "    dataset = readData(path, label_col)\n",
    "    if(k_range is not None and seed_range is not None):\n",
    "        file_name = fileNameFromPath(path) + '_' + method + '_' + 'k(' + str(k_range[0]) + ',' + str(k_range[1]) + ')' + '_' + 'seed(' + str(seed_range[0]) + ',' + str(seed_range[1]) + ').csv'\n",
    "        for x in range(k_range[0], k_range[1]):\n",
    "            parameters[\"n_clusters\"] = x\n",
    "            for y in range(seed_range[0], seed_range[1]):\n",
    "                parameters[\"random_state\"] = y\n",
    "                cluster_method = cluster(method, parameters)\n",
    "                cluster_method.fit(dataset)\n",
    "                scores = getScores(dataset, cluster_method.labels_)\n",
    "                writeData(file_name, k = str(x), seed = str(y), slt_score = str(scores[0]), db_score = str(scores[1]))\n",
    "    elif(k_range is not None and seed_range is None):\n",
    "        file_name = fileNameFromPath(path) + '_' + method + '_' + 'k(' + str(k_range[0]) + ',' + str(k_range[1]) + ').csv'\n",
    "        for x in range(k_range[0], k_range[1]):\n",
    "            parameters[\"n_clusters\"] = x\n",
    "            cluster_method = cluster(method, parameters)\n",
    "            cluster_method.fit(dataset)\n",
    "            scores = getScores(dataset, cluster_method.labels_)\n",
    "            writeData(file_name, k = str(x), slt_score = str(scores[0]), db_score = str(scores[1]))\n",
    "    elif(k_range is None and seed_range is not None):\n",
    "        file_name = fileNameFromPath(path) + '_' + method + '_' + 'seed(' + str(seed_range[0]) + ',' + str(seed_range[1]) + ').csv'\n",
    "        for y in range(seed_range[0], seed_range[1]):\n",
    "            parameters[\"random_state\"] = y\n",
    "            cluster_method = cluster(method, parameters)\n",
    "            cluster_method.fit(dataset)\n",
    "            scores = getScores(dataset, cluster_method.labels_)\n",
    "            writeData(file_name, seed = str(y), slt_score = str(scores[0]), db_score = str(scores[1]))\n",
    "    else:\n",
    "        file_name = fileNameFromPath(path) + '_' + method + '.csv'\n",
    "        cluster_method = cluster(method, parameters)\n",
    "        cluster_method.fit(dataset)\n",
    "        scores = getScores(dataset, cluster_method.labels_)\n",
    "        writeData(file_name, slt_score = str(scores[0]), db_score = str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    analyze(\"iris.csv\", \"KMeans\", k_range = (2, 21), seed_range = (1, 21), label_col = \"variety\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = readData(\"iris.csv\", \"variety\")\n",
    "cluster_method = cluster(\"KMeans\", {\"n_clusters\" : 4, \"random_state\": 2})\n",
    "cluster_method.fit(dataset)\n",
    "print(cluster_method.labels_)\n",
    "print(getScores(dataset, cluster_method.labels_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
